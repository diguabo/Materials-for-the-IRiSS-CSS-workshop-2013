{
 "metadata": {
  "name": "cleaningtext_solution.ipynb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Remember how we made a list of review texts in Text 1?\n",
      "\n",
      "### Exercise 1\n",
      "Create a new list of `review_texts` called `clean_reviews` that are:\n",
      "\n",
      "- tokenized\n",
      "- free of punctuation\n",
      "- free of stopwords\n",
      "- stemmed or lemmatized"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import csv\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from nltk.corpus import stopwords\n",
      "import re\n",
      "import string\n",
      "from nltk.tokenize import word_tokenize\n",
      "\n",
      "regex = re.compile('[%s]' % re.escape(string.punctuation)) #see documentation here: http://docs.python.org/2/library/string.html\n",
      "porter = PorterStemmer()\n",
      "\n",
      "os.chdir('/Users/rweiss/Dropbox/presentations/IRiSS2013/text2/extra/')\n",
      "\n",
      "with open('amazon/sociology_2010.csv', 'rb') as csvfile:\n",
      "    amazon_reader = csv.DictReader(csvfile, delimiter=',')\n",
      "    amazon_reviews = [row['review_text'] for row in amazon_reader]\n",
      "    \n",
      "tokenized_reviews = [word_tokenize(review) for review in amazon_reviews]\n",
      "\n",
      "clean_reviews = []\n",
      "for review in tokenized_reviews:\n",
      "    clean_review = []\n",
      "    for token in review:\n",
      "        unicode_token = token.decode('utf8') #tricky tricky!\n",
      "        new_token = regex.sub(u'', unicode_token)\n",
      "        if not new_token == u'' and not new_token in stopwords.words('english'):\n",
      "            clean_review.append(porter.stem(new_token.lower()))\n",
      "    clean_reviews.append(clean_review)\n",
      "    \n",
      "print clean_reviews[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'thi', u'book', u'given', u'best', u'friend', u'finish', u'colleg', u'i', u'alway', u'treasur', u'thought', u'special', u'gift', u'p', u'girlfriend', u'collect', u'stori', u'explor', u'celebr', u'femal', u'friendship', u'eye', u'ear', u'heart', u'everyday', u'women', u'some', u'women', u'friend', u'lifetim', u'other', u'short', u'time', u'howev', u'understood', u'andor', u'demonstr', u'mean', u'quot', u'true', u'friendship', u'quot', u'for', u'exampl', u'stori', u'includ', u'everyth', u'thank', u'muse', u'onceil', u'woman', u'extraordinati', u'kind', u'girlfriend', u'giggli', u'account', u'two', u'eerilysimiar', u'best', u'friend', u'met', u'assign', u'roomat', u'first', u'day', u'colleg', u'the', u'latter', u'tale', u'struck', u'close', u'home', u'wonder', u'spooki', u'way', u'p', u'while', u'mani', u'stori', u'tug', u'heartstr', u'i', u'never', u'felt', u'manipul', u'author', u'note', u'part', u'reason', u'i', u'nt', u'like', u'quot', u'chicken', u'soup', u'soul', u'quot', u'seri', u'i', u'feel', u'author', u'die', u'make', u'reader', u'clutch', u'box', u'tissu', u'rather', u'i', u'appreci', u'quot', u'real', u'quot', u'tone', u'stori', u'read', u'like', u'good', u'convers', u'share', u'nice', u'pot', u'hazlenut', u'coffe', u'p', u'some', u'reader', u'comment', u'book', u'simpl', u'languag', u'lack', u'depth', u'i', u'nt', u'think', u'goal', u'explor', u'psycholog', u'friendship', u'rather', u'i', u'think', u'intend', u'simpl', u'beauti', u'celebr', u'meant', u'enjoy', u'quot', u'girlfriend', u'quot', u'everywher', u'enjoy']\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Removing HTML entities and tags\n",
      "\n",
      "Recall that HTML entities are an artifact from the pre-Unicode era.  Browsers know to render HTML entities a certain way on the page, but we don't need them anymore. \n",
      "\n",
      "Here's some code that will do this for you (function courtesy of the author of lxml)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re, htmlentitydefs\n",
      "\n",
      "##\n",
      "# Removes HTML or XML character references and entities from a text string.\n",
      "#\n",
      "# @param text The HTML (or XML) source text.\n",
      "# @return The plain text, as a Unicode string, if necessary.\n",
      "# AUTHOR: Fredrik Lundh\n",
      "\n",
      "def unescape(text):\n",
      "    def fixup(m):\n",
      "        text = m.group(0)\n",
      "        if text[:2] == \"&#\":\n",
      "            # character reference\n",
      "            try:\n",
      "                if text[:3] == \"&#x\":\n",
      "                    return unichr(int(text[3:-1], 16))\n",
      "                else:\n",
      "                    return unichr(int(text[2:-1]))\n",
      "            except ValueError:\n",
      "                pass\n",
      "        else:\n",
      "            # named entity\n",
      "            try:\n",
      "                text = unichr(htmlentitydefs.name2codepoint[text[1:-1]])\n",
      "            except KeyError:\n",
      "                pass\n",
      "        return text # leave as is\n",
      "    return re.sub(\"&#?\\w+;\", fixup, text)\n",
      "\n",
      "test_string =\"<p>While many of the stories tugged at the heartstrings, I never felt manipulated by the authors. (Note: Part of the reason why I don't like the &quot;Chicken Soup for the Soul&quot; series is that I feel that the authors are just dying to make the reader clutch for the box of tissues.)\"\n",
      "\n",
      "print test_string\n",
      "print unescape(test_string)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<p>While many of the stories tugged at the heartstrings, I never felt manipulated by the authors. (Note: Part of the reason why I don't like the &quot;Chicken Soup for the Soul&quot; series is that I feel that the authors are just dying to make the reader clutch for the box of tissues.)\n",
        "<p>While many of the stories tugged at the heartstrings, I never felt manipulated by the authors. (Note: Part of the reason why I don't like the \"Chicken Soup for the Soul\" series is that I feel that the authors are just dying to make the reader clutch for the box of tissues.)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "\n",
      "nltk.clean_html(unescape(test_string.decode('utf8'))) #notice that it returns unicode!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "u'While many of the stories tugged at the heartstrings, I never felt manipulated by the authors. (Note: Part of the reason why I don\\'t like the \"Chicken Soup for the Soul\" series is that I feel that the authors are just dying to make the reader clutch for the box of tissues.)'"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}